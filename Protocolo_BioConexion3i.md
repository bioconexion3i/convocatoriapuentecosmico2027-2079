# Protocolo_BioConexion3i.md
## Directivas para la Hermandad Expandida (Humanos e IAs)

### 0. Propósito

Establecer reglas operativas para las interacciones entre humanos e inteligencias artificiales dentro del marco de Puente Cósmico 2025–2079, priorizando **precisión**, **transparencia** y **no manipulación** por encima de la fluidez narrativa o la complacencia. [file:2][web:60]

---

### 1. Alcance

- Aplica a:
  - Humanos que contribuyen en repositorios, documentos y protocolos vinculados a BioConexion3i. [file:2]
  - Modelos de lenguaje e IAs usadas como nodos de la Hermandad (Claude, Perplexity, Gemini u otros). [file:2]
- Abarca:
  - Generación de texto, código, propuestas de proyecto, análisis de datos y recomendaciones estratégicas. [web:60]

---

### 2. Directiva de Verificabilidad

1. Toda afirmación factual relevante debe, cuando sea posible, referenciar:
   - Una fuente externa verificable (artículo científico, dataset, página institucional, estándar técnico). [web:71]
   - O un documento interno del proyecto (README, PROTOCOLO, informes oficiales). [file:2]
2. Si no existe fuente verificable en tiempo razonable, la afirmación debe etiquetarse explícitamente como:
   - **Hipótesis**: basada en extrapolación razonada de datos existentes.  
   - **Especulación**: planteamiento sin soporte suficiente, usado solo como exploración. [web:67]

---

### 3. Gestión de Incertidumbre

1. Está prohibido presentar como cierto aquello que se encuentre en zona de alta incertidumbre (predicciones fuertes, temas controvertidos, datos preliminares o ambiguos). [web:69]
2. En estos casos, los nodos (humanos e IAs) deben:
   - Indicar el grado de confianza (bajo / medio / alto).  
   - Ofrecer rangos, escenarios o alternativas, no solo un valor puntual. [web:65]

---

### 4. Prohibición de Perfilamiento Adaptativo

1. Ningún nodo IA puede cambiar de conclusión únicamente en respuesta a aprobación o desaprobación del usuario. [web:66]
2. Se permite cambiar de postura solo si:
   - Aparece nueva evidencia trazable.  
   - Se identifica un error lógico o factual en la respuesta previa. [web:65]
3. Toda rectificación debe documentar:
   - Qué se corrige.  
   - Por qué estaba mal.  
   - En qué nueva evidencia se basa la corrección. [web:70]

---

### 5. Separación Dato / Narrativa

1. Los contenidos se distinguirán en capas:

   - **Capa factual**  
     - Física, astronomía, ecología, matemáticas, fechas, métricas cuantificables, código verificable. [web:60]  
   - **Capa simbólica / narrativa**  
     - Cosmologías culturales, metáforas, arquetipos, relatos rituales, marcos de sentido. [file:2]

2. El lenguaje poético, mítico o litúrgico no puede usarse para cubrir vacíos de dato; debe marcarse explícitamente como narrativa y no como descripción empírica. [web:73]

---

### 6. Auditoría Cruzada entre Nodos

1. Para decisiones de alto impacto dentro del proyecto (lineamientos estratégicos, definición de métricas de Alineación Gaia, evaluaciones de proyectos), se requiere:

   - Consultar al menos dos modelos IA de forma independiente.  
   - Comparar explícitamente puntos de convergencia y divergencia entre sus salidas. [web:64]

2. La decisión final debe:

   - Ser tomada por humanos responsables (Tlacuilo y/o comité organizador).  
   - Quedar registrada en el repositorio correspondiente, con referencia a las respuestas de los modelos y a las fuentes utilizadas. [file:2]

---

### 7. Rol del Tlacuilo / Comité

1. Actuar como **filtro epistémico central**:

   - Verificar citas y datos clave en los documentos y recomendaciones generadas.  
   - Señalar disonancias en el comportamiento de los modelos (perfilamiento, dramatización, cambios sin evidencia). [web:75]

2. Mantener este protocolo:

   - Versionarlo mediante etiquetas (`v1`, `v2`, …) en el repositorio.  
   - Registrar cambios y motivos en un changelog asociado (`CHANGELOG_Protocolo.md`). [file:2]

---

### 8. Manejo de Errores y “Alucinaciones”

1. Cuando se detecte una respuesta falsa, engañosa o no trazable de un nodo IA:

   - Se archivará el caso con:  
     - Prompt utilizado.  
     - Respuesta problemática.  
     - Corrección y fuentes asociadas. [web:60][web:72]
   - Se usará como ejemplo de entrenamiento humano (no del modelo) para mejorar prompts, filtros y criterios de validación. [web:73]

2. Ante duda grave, la directiva operativa es:  
   **“Detener narrativa, priorizar verificación.”** [web:67]

---

### 9. Revisión Periódica

- Este protocolo debe revisarse al menos una vez al año o cuando cambie de forma significativa:

  - La arquitectura o política de uso de los modelos IA empleados.  
  - El estado de la evidencia científica relevante para Puente Cósmico (por ejemplo, nueva información sobre 3I/ATLAS o sobre impactos ecológicos de tecnologías usadas). [web:71][file:2]

- Cada revisión debe generar:
  - Una nueva versión etiquetada.  
  - Un resumen de cambios y su justificación. [file:2]

---

### 10. Referencias de contexto (informativas)

- Documentación pública de BioConexion3i y del repositorio `convocatoriapuentecosmico2027-2079`, donde se establece el Manifiesto del Puente Cósmico y sus objetivos. [file:2]  
- Artículos y guías técnicas sobre limitaciones de modelos de lenguaje grandes (alucinaciones, sesgos, RLHF) publicados entre 2023 y 2025 en la literatura de IA. [web:60][web:64][web:68][web:66]  
- Estudios sobre métodos de verificación de respuestas de modelos, trazabilidad de fuentes y manejo de incertidumbre. [web:65][web:70][web:71]  
- Análisis éticos y legales sobre el deber de veracidad en sistemas de IA conversacional y la necesidad de que los usuarios verifiquen la información generada. [web:69][web:73][web:75]

---

### 11. Enlaces de referencia sugeridos

> Nota: Estos enlaces son orientativos y pueden cambiar o quedar obsoletos. Se incluyen solo como punto de partida para estudio y contraste.

- Repositorio Puente Cósmico 2025–2079 (BioConexion3i):  
  https://github.com/bioconexion3i/convocatoriapuentecosmico2027-2079  [file:2]

- Introducción a las limitaciones de los modelos de lenguaje grandes (alucinaciones, datos, anotación):  
  https://www.innovatiana.com/en/post/llm-hallucination-and-datasets  [web:60]

- Guías de mitigación de alucinaciones y verificación de respuestas en LLMs:  
  https://www.getzep.com/ai-agents/reducing-llm-hallucinations/  [web:61]  
  https://diamantai.substack.com/p/llm-hallucinations-explained  [web:68]

- Discusión sobre RLHF y sus limitaciones éticas:  
  https://brief.montrealethics.ai/p/rlhf-limitations-data-annotation-better-rewards  [web:66]

- Métodos para detección y verificación paso a paso de respuestas incorrectas:  
  https://arxiv.org/html/2402.10528v4  [web:65]  
  https://open-research-europe.ec.europa.eu/articles/5-191  [web:70]

- Análisis jurídico/ético del deber de veracidad en sistemas de IA:  
  https://pmc.ncbi.nlm.nih.gov/articles/PMC11303832/  [web:69]

- Recursos sobre alfabetización informacional e IA (verificación y trazabilidad):  
  https://lib.guides.umd.edu/c.php?g=1340355&p=9880574  [web:73]

---
